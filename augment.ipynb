{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_dataset(input_dir, output_dir, target_size=(224, 224), target_per_class=2000):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'Normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'OSCC'), exist_ok=True)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        brightness_range=[0.7, 1.3]\n",
    "    )\n",
    "    \n",
    "    # Process each class\n",
    "    for class_name in ['Normal', 'OSCC']:\n",
    "        print(f\"\\nProcessing {class_name} class...\")\n",
    "        \n",
    "        # Get list of original images\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        images = glob.glob(os.path.join(class_path, '*'))\n",
    "        num_orig = len(images)\n",
    "        print(f\"Found {num_orig} original images\")\n",
    "        \n",
    "        # Calculate how many augmented images we need per original image\n",
    "        augmentations_per_image = (target_per_class - num_orig) // num_orig + 1\n",
    "        \n",
    "        # Counter for generated images\n",
    "        generated_count = 0\n",
    "        \n",
    "        # Copy original images first\n",
    "        for img_path in images:\n",
    "            img_name = os.path.basename(img_path)\n",
    "            new_path = os.path.join(output_dir, class_name, img_name)\n",
    "            tf.io.gfile.copy(img_path, new_path, overwrite=True)\n",
    "            generated_count += 1\n",
    "        \n",
    "        # Generate augmented images\n",
    "        for img_path in images:\n",
    "            # Load and resize image\n",
    "            img = tf.keras.preprocessing.image.load_img(\n",
    "                img_path, \n",
    "                target_size=target_size\n",
    "            )\n",
    "            x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            \n",
    "            # Generate augmented images\n",
    "            batch_count = 0\n",
    "            for batch in datagen.flow(\n",
    "                x, \n",
    "                batch_size=1,\n",
    "                save_to_dir=os.path.join(output_dir, class_name),\n",
    "                save_prefix=f'aug_{os.path.splitext(os.path.basename(img_path))[0]}',\n",
    "                save_format='jpg'\n",
    "            ):\n",
    "                batch_count += 1\n",
    "                generated_count += 1\n",
    "                \n",
    "                # Break when we've generated enough images for this original image\n",
    "                if batch_count >= augmentations_per_image:\n",
    "                    break\n",
    "                \n",
    "                # Break if we've reached our target\n",
    "                if generated_count >= target_per_class:\n",
    "                    break\n",
    "            \n",
    "            if generated_count >= target_per_class:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {generated_count} total images for {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Normal class...\n",
      "Found 89 original images\n",
      "Generated 2000 total images for Normal\n",
      "\n",
      "Processing OSCC class...\n",
      "Found 439 original images\n",
      "Generated 2000 total images for OSCC\n",
      "\n",
      "Final count for Normal: 1998 images\n",
      "\n",
      "Final count for OSCC: 2000 images\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_dir = 'dataset'\n",
    "    output_dir = 'augmented_dataset'\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    target_per_class = 2000\n",
    "    \n",
    "    create_augmented_dataset(input_dir, output_dir, target_size, target_per_class)\n",
    "    \n",
    "    for class_name in ['Normal', 'OSCC']:\n",
    "        path = os.path.join(output_dir, class_name)\n",
    "        num_images = len(glob.glob(os.path.join(path, '*')))\n",
    "        print(f\"\\nFinal count for {class_name}: {num_images} images\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
