{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport timm\nimport numpy as np\nimport cv2\nfrom pathlib import Path\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nimport os\nfrom tqdm import tqdm\nimport pandas as pd\n\ntorch.cuda.empty_cache()\n\ndef create_dataset_df(base_path):\n    \"\"\"Create a DataFrame containing image paths and labels\"\"\"\n    data = []\n    \n    # First Set (100x)\n    first_set = os.path.join(base_path, 'First Set')\n    normal_100x = os.path.join(first_set, '100x Normal Oral Cavity Histopathological Images')\n    oscc_100x = os.path.join(first_set, '100x OSCC Histopathological Images')\n    \n    # Add 100x normal images\n    for img_name in os.listdir(normal_100x):\n        if img_name.endswith(('.jpg')):\n            data.append({\n                'path': os.path.join(normal_100x, img_name),\n                'label': 0,  # normal\n                'magnification': '100x'\n            })\n    \n    # Add 100x OSCC images\n    for img_name in os.listdir(oscc_100x):\n        if img_name.endswith(('.jpg')):\n            data.append({\n                'path': os.path.join(oscc_100x, img_name),\n                'label': 1,  # OSCC\n                'magnification': '100x'\n            })\n    \n    # Second Set (400x)\n    second_set = os.path.join(base_path, 'Second Set')\n    normal_400x = os.path.join(second_set, '400x Normal Oral Cavity Histopathological Images')\n    oscc_400x = os.path.join(second_set, '400x OSCC Histopathological Images')\n    \n    # Add 400x normal images\n    for img_name in os.listdir(normal_400x):\n        if img_name.endswith(('.jpg')):\n            data.append({\n                'path': os.path.join(normal_400x, img_name),\n                'label': 0,  # normal\n                'magnification': '400x'\n            })\n    \n    # Add 400x OSCC images\n    for img_name in os.listdir(oscc_400x):\n        if img_name.endswith(('.jpg')):\n            data.append({\n                'path': os.path.join(oscc_400x, img_name),\n                'label': 1,  # OSCC\n                'magnification': '400x'\n            })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    print(f\"Class distribution:\\n{df['label'].value_counts()}\")\n    print(f\"Magnification distribution:\\n{df['magnification'].value_counts()}\")\n    return df\n\nclass OralCancerDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image = cv2.imread(row['path'])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        return image, row['label']\n\nclass ConvNextModel(nn.Module):\n    def __init__(self, num_classes=2):\n        super().__init__()\n        self.convnext = timm.create_model('convnext_base', pretrained=True, num_classes=num_classes)\n        \n        # Modify head for binary classification\n        self.convnext.head.fc = nn.Sequential(\n            nn.LayerNorm(1024),\n            nn.Dropout(0.1),\n            nn.Linear(1024, num_classes)\n        )\n\n    def forward(self, x):\n        return self.convnext(x)\n\ndef get_transforms(is_train=True):\n    \"\"\"Get transforms for training/validation\"\"\"\n    size = 224  # ConvNext optimal size\n    \n    if is_train:\n        return A.Compose([\n            A.RandomResizedCrop(size, size, scale=(0.8, 1.0)),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.1, rotate_limit=45),\n            A.OneOf([\n                A.GaussNoise(var_limit=(10.0, 50.0)),\n                A.GaussianBlur(blur_limit=(3, 7)),\n            ], p=0.5),\n            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n            A.Normalize(),\n            ToTensorV2()\n        ])\n    else:\n        return A.Compose([\n            A.Resize(size, size),\n            A.Normalize(),\n            ToTensorV2()\n        ])\n\ndef train_epoch(model, train_loader, optimizer, criterion, device, epoch):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}')\n    \n    for images, labels in progress_bar:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        progress_bar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'acc': f'{100.*correct/total:.2f}%'\n        })\n    \n    return total_loss / len(train_loader), correct / total\n\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0\n    val_preds = []\n    val_labels = []\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            \n            probs = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n            val_preds.extend(probs)\n            val_labels.extend(labels.cpu().numpy())\n    \n    val_preds = np.array(val_preds)\n    val_labels = np.array(val_labels)\n    \n    auc_roc = roc_auc_score(val_labels, val_preds)\n    pred_labels = (val_preds > 0.5).astype(int)\n    cm = confusion_matrix(val_labels, pred_labels)\n    \n    sensitivity = cm[1,1] / (cm[1,1] + cm[1,0])\n    specificity = cm[0,0] / (cm[0,0] + cm[0,1])\n    \n    return {\n        'loss': val_loss / len(val_loader),\n        'auc_roc': auc_roc,\n        'sensitivity': sensitivity,\n        'specificity': specificity\n    }\n\ndef main():\n    # Set random seed for reproducibility\n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    # Parameters\n    BATCH_SIZE = 16  # Increased for GPU\n    NUM_EPOCHS = 30\n    BASE_PATH = '/kaggle/input/histopathological-imaging-oral-cancer-analysis'  # Kaggle dataset path\n    \n    # Create dataset DataFrame\n    df = create_dataset_df(BASE_PATH)\n    \n    # Split data into train/validation\n    from sklearn.model_selection import train_test_split\n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n    \n    # Create datasets\n    train_dataset = OralCancerDataset(train_df, transform=get_transforms(is_train=True))\n    val_dataset = OralCancerDataset(val_df, transform=get_transforms(is_train=False))\n    \n    # Create data loaders\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                            num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n                          num_workers=2, pin_memory=True)\n    \n    # Initialize model\n    device = torch.device('cuda')\n    model = ConvNextModel().to(device)\n    \n    # Calculate class weights for balanced loss\n    class_counts = df['label'].value_counts()\n    total_samples = len(df)\n    class_weights = torch.FloatTensor([total_samples/(2*class_counts[i]) for i in range(2)]).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # Initialize optimizer and scheduler\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n    scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n    \n    # Training loop\n    best_auc = 0\n    for epoch in range(NUM_EPOCHS):\n        # Train\n        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, epoch)\n        \n        # Validate\n        metrics = validate(model, val_loader, criterion, device)\n        \n        print(f'\\nEpoch {epoch + 1}/{NUM_EPOCHS}:')\n        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n        print(f'Val Loss: {metrics[\"loss\"]:.4f}')\n        print(f'Val AUC-ROC: {metrics[\"auc_roc\"]:.4f}')\n        print(f'Sensitivity: {metrics[\"sensitivity\"]:.4f}')\n        print(f'Specificity: {metrics[\"specificity\"]:.4f}')\n        \n        # Update scheduler\n        scheduler.step()\n        \n        # Save best model\n        if metrics['auc_roc'] > best_auc:\n            best_auc = metrics['auc_roc']\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_auc': best_auc,\n            }, 'best_model.keras')\n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T09:18:20.947861Z","iopub.execute_input":"2025-02-09T09:18:20.948138Z","iopub.status.idle":"2025-02-09T09:48:17.994993Z","shell.execute_reply.started":"2025-02-09T09:18:20.948114Z","shell.execute_reply":"2025-02-09T09:48:17.994093Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"Total images: 1224\nClass distribution:\nlabel\n1    934\n0    290\nName: count, dtype: int64\nMagnification distribution:\nmagnification\n400x    696\n100x    528\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d4350d590641948a605421cc4c316e"}},"metadata":{}},{"name":"stderr","text":"Epoch 1: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s, loss=0.0736, acc=61.39%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/30:\nTrain Loss: 0.6833, Train Acc: 0.6139\nVal Loss: 0.4435\nVal AUC-ROC: 0.8681\nSensitivity: 0.7380\nSpecificity: 0.8793\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.3384, acc=71.71%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/30:\nTrain Loss: 0.5269, Train Acc: 0.7171\nVal Loss: 0.4083\nVal AUC-ROC: 0.9096\nSensitivity: 0.8877\nSpecificity: 0.7241\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.1651, acc=83.15%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/30:\nTrain Loss: 0.3948, Train Acc: 0.8315\nVal Loss: 0.4632\nVal AUC-ROC: 0.9198\nSensitivity: 0.9572\nSpecificity: 0.6379\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0299, acc=84.17%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/30:\nTrain Loss: 0.3768, Train Acc: 0.8417\nVal Loss: 0.4389\nVal AUC-ROC: 0.9346\nSensitivity: 0.9572\nSpecificity: 0.7241\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0017, acc=86.82%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/30:\nTrain Loss: 0.3325, Train Acc: 0.8682\nVal Loss: 0.4011\nVal AUC-ROC: 0.9245\nSensitivity: 0.9144\nSpecificity: 0.7241\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s, loss=0.9132, acc=85.39%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/30:\nTrain Loss: 0.3151, Train Acc: 0.8539\nVal Loss: 0.3393\nVal AUC-ROC: 0.9340\nSensitivity: 0.8128\nSpecificity: 0.8966\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0122, acc=89.68%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/30:\nTrain Loss: 0.2610, Train Acc: 0.8968\nVal Loss: 0.4226\nVal AUC-ROC: 0.9371\nSensitivity: 0.9037\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0056, acc=92.54%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/30:\nTrain Loss: 0.2052, Train Acc: 0.9254\nVal Loss: 0.3564\nVal AUC-ROC: 0.9480\nSensitivity: 0.9091\nSpecificity: 0.7586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0470, acc=93.56%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/30:\nTrain Loss: 0.1762, Train Acc: 0.9356\nVal Loss: 0.3221\nVal AUC-ROC: 0.9407\nSensitivity: 0.8663\nSpecificity: 0.8276\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0284, acc=93.56%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/30:\nTrain Loss: 0.1666, Train Acc: 0.9356\nVal Loss: 0.3689\nVal AUC-ROC: 0.9277\nSensitivity: 0.8824\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0636, acc=94.38%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/30:\nTrain Loss: 0.1325, Train Acc: 0.9438\nVal Loss: 0.3667\nVal AUC-ROC: 0.9551\nSensitivity: 0.9465\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0589, acc=95.71%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/30:\nTrain Loss: 0.1103, Train Acc: 0.9571\nVal Loss: 0.4115\nVal AUC-ROC: 0.9498\nSensitivity: 0.9412\nSpecificity: 0.8276\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 62/62 [00:51<00:00,  1.22it/s, loss=0.0087, acc=95.71%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/30:\nTrain Loss: 0.1057, Train Acc: 0.9571\nVal Loss: 0.3859\nVal AUC-ROC: 0.9415\nSensitivity: 0.9144\nSpecificity: 0.7931\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s, loss=0.0006, acc=96.42%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/30:\nTrain Loss: 0.0903, Train Acc: 0.9642\nVal Loss: 0.5627\nVal AUC-ROC: 0.9421\nSensitivity: 0.9358\nSpecificity: 0.6897\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0014, acc=97.04%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/30:\nTrain Loss: 0.0781, Train Acc: 0.9704\nVal Loss: 0.4651\nVal AUC-ROC: 0.9560\nSensitivity: 0.9358\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0017, acc=96.22%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16/30:\nTrain Loss: 0.1036, Train Acc: 0.9622\nVal Loss: 0.4900\nVal AUC-ROC: 0.9446\nSensitivity: 0.9251\nSpecificity: 0.8276\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s, loss=0.0013, acc=97.85%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17/30:\nTrain Loss: 0.0658, Train Acc: 0.9785\nVal Loss: 0.5215\nVal AUC-ROC: 0.9422\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0037, acc=98.77%] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18/30:\nTrain Loss: 0.0486, Train Acc: 0.9877\nVal Loss: 0.5516\nVal AUC-ROC: 0.9451\nSensitivity: 0.9572\nSpecificity: 0.7586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0187, acc=98.16%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19/30:\nTrain Loss: 0.0547, Train Acc: 0.9816\nVal Loss: 0.5771\nVal AUC-ROC: 0.9461\nSensitivity: 0.9305\nSpecificity: 0.8276\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0004, acc=97.75%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20/30:\nTrain Loss: 0.0551, Train Acc: 0.9775\nVal Loss: 0.5221\nVal AUC-ROC: 0.9473\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0001, acc=98.57%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21/30:\nTrain Loss: 0.0321, Train Acc: 0.9857\nVal Loss: 0.6148\nVal AUC-ROC: 0.9538\nSensitivity: 0.9519\nSpecificity: 0.7069\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0118, acc=98.88%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22/30:\nTrain Loss: 0.0347, Train Acc: 0.9888\nVal Loss: 0.5533\nVal AUC-ROC: 0.9436\nSensitivity: 0.9144\nSpecificity: 0.8103\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0784, acc=98.67%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23/30:\nTrain Loss: 0.0290, Train Acc: 0.9867\nVal Loss: 0.5986\nVal AUC-ROC: 0.9516\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s, loss=0.0001, acc=99.18%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24/30:\nTrain Loss: 0.0170, Train Acc: 0.9918\nVal Loss: 0.6213\nVal AUC-ROC: 0.9533\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.2694, acc=98.88%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25/30:\nTrain Loss: 0.0241, Train Acc: 0.9888\nVal Loss: 0.6377\nVal AUC-ROC: 0.9514\nSensitivity: 0.9358\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0001, acc=99.08%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26/30:\nTrain Loss: 0.0333, Train Acc: 0.9908\nVal Loss: 0.6357\nVal AUC-ROC: 0.9516\nSensitivity: 0.9412\nSpecificity: 0.7931\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0001, acc=98.57%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27/30:\nTrain Loss: 0.0242, Train Acc: 0.9857\nVal Loss: 0.6470\nVal AUC-ROC: 0.9523\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0033, acc=99.08%] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28/30:\nTrain Loss: 0.0189, Train Acc: 0.9908\nVal Loss: 0.6493\nVal AUC-ROC: 0.9525\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.5009, acc=98.88%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29/30:\nTrain Loss: 0.0305, Train Acc: 0.9888\nVal Loss: 0.6477\nVal AUC-ROC: 0.9524\nSensitivity: 0.9412\nSpecificity: 0.7759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s, loss=0.0022, acc=98.88%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30/30:\nTrain Loss: 0.0272, Train Acc: 0.9888\nVal Loss: 0.6507\nVal AUC-ROC: 0.9524\nSensitivity: 0.9412\nSpecificity: 0.7586\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}